# Chapter 2: Regression and model validation

*First look at data wrangling and analysis*

## Data wrangling

Reading the full data and naming it "learning2014".

```{r}
learning2014 <- read.table("http://www.helsinki.fi/~kvehkala/JYTmooc/JYTOPKYS3-data.txt", sep="\t", header = TRUE)
```

Data consists of 183 rows (observations) and 60 columns (variables). 

```{r}
dim(learning2014)
```

The structure of the data:

```{r}
str(learning2014)
```

Acces the dplyr library:

```{r}
library(dplyr)
```

Combinig the questions related to deep, surface and strategic learning.

```{r}
deep_questions <- c("D03", "D11", "D19", "D27", "D07", "D14", "D22", "D30","D07","D14","D22","D30")
surface_questions <-c("SU02","SU10","SU18","SU26", "SU05","SU13","SU21","SU29","SU08","SU16","SU24","SU32")
strategic_questions <- c("ST01","ST09","ST17","ST25","ST04","ST12","ST20","ST28")
```

Selecting the columns for "deep" and taking average to scale the variable.

```{r}
deep_columns <- select(learning2014, one_of(deep_questions))
learning2014$deep <- rowMeans(deep_columns)
```

Selecting the columns for "surf" and taking average to scale the variable.

```{r}
surface_columns <- select(learning2014, one_of(surface_questions))
learning2014$surf <- rowMeans(surface_columns)
```

Selecting the columns for "stra" and taking average to scale the variable.

``` {r}
strategic_columns <- select(learning2014, one_of(strategic_questions))
learning2014$stra <- rowMeans(strategic_columns)
```

Selecting the variables gender, age, attitude towards statistics, exam points and the three new summary variables to dataset.

```{r}
keep_columns <- c("gender", "Age", "Attitude", "deep", "stra", "surf", "Points")
new_learning2014 <- select(learning2014, one_of(keep_columns))
```

Removing the observations with 0 exam points:

```{r}
new_learning2014 <- filter(new_learning2014, Points > 0)
```

Testing: The dimension and structure seem to be correct.

```{r}
dim(new_learning2014)
str(new_learning2014)
```

Saving the dataset:

```{r}
write.table(new_learning2014, "learning2014.txt", sep = "\t")
```

Reading the set again and after that testing it is working properly:

```{r}
str(new_learning2014)
dim(new_learning2014)
head(new_learning2014)
```

...and everything seems to be ok and I'm able move forward to the analysis part of the exercises.

## Analysis

1. Describing the data

I'm using the dataset from the previous part of the exercise. The data is part of a larger "Approaches to Learning" -survey. Here is used only a few backgroud variables (age and gender), variable measuring global attitude toward statistics, exam points and sum variables measuring student's deep, surface and strategic learning.

When observations with zero exam points are excluded, the total N of the data is 166.

2. Descriptive statistics

First thing to do with the data is to see some descriptive statistics.

```{r}
summary(new_learning2014)
```

There are 110 female and 56 male respondents in the data. Tha average age is 25.5 when the youngest respondent is 17 and the oldest 55 years old. The measured mean attitude towards statistics is 31.4, ranging from 14 to 50. Exam points range (when 0 points excluded) from 7 to 33 and the average is 22.7. The summary variables measuring deep, strategic and surface learning are scaled from 1 to 5. In deep learning the averige is 3.8 (minimum 1.6, maximum 4.9), strategic learning 3.1 (min 1.3, max 5.0) and surface learning 2.8 (min 1.6, max 4.3). 

As a graphical overview I made a scatter plot of all the variables according to background variables.

```{r}
plot(new_learning2014$Attitude, new_learning2014$Age, col=new_learning2014$gender, title("Figure 1: Attitude according to age and gender"))
```

Males and older respondents seem to have more attitude towards statistics. 

```{r}
plot(new_learning2014$Points, new_learning2014$Age, col=new_learning2014$gender, title("Figure 2: Exam points according to age and gender"))
```

There is a lot of variation in exam points, no clear trends visible. Especially in the lower points there are both genders and respondents of all ages represent.

```{r}
plot(new_learning2014$deep, new_learning2014$Age, col=new_learning2014$gender, title("Figure 3: Deep learning according to age and gender"))
```

In deep learning there is a clear impact of age: older respondets tend to use learning methods that are connected with deep learning.

```{r}
plot(new_learning2014$stra, new_learning2014$Age, col=new_learning2014$gender, title("Figure 4: Strategic learning according to age and gender"))
```

In strategic learning the impact of age is not at visible as above, but some connection is visible.

```{r}
plot(new_learning2014$surf, new_learning2014$Age, col=new_learning2014$gender, title("Figure 5: Surface learning according to age and gender"))
```

Surface learning is less usual than the other two, but surprisingly there are no clear differences according to age nor gender.

3. Regression model

Creating a regression model with three explanatory variables (attitude, deep learning and strategic learning). The dependent variable is exam points. Checking the summary of the model.

```{r}
rg_model <- lm(Points ~ Attitude + deep + stra, data = new_learning2014)
summary(rg_model)
```

The summary table tells us that when attitude rises one point the exam point increses by 0.35 points. The similar connecton with deep learning is -0.90 and with strategic learning 0.98. 

The only statistically significant variable is the attitude. I tried surface learning and both age and gender as well, but they were not statistically significant in the analysis. In this case I remove all the other variables but the attitude.

4. Summary of the fitted model

The final regression model is simple with only one independet, explanatory variable.

```{r}
rg_model2 <- lm(Points ~ Attitude, data = new_learning2014)
summary(rg_model2)
```

The effect of attitude stays the same as above: when the level of attitude grows one point, the exam points increse by 0.35 points. The effect is not very strong, but it is statistically significant, which means that there is very low change to make the wrong assumption about the relationship of these two variables.

5. Diagnostic plots

Residuals vs. Fitted values:

In this diagnostic plot we examine if the errors are just errors and not depending on the explanatory variable. This means that there should not be any kind of pattern in the plot - and luckily there is not.

```{r}
plot(rg_model2, which = 1)
```

Normal QQ-plot:

The plot shows that the residuals are close enough normally distributed. The residuals follow the line quite well. 

```{r}
plot(rg_model2, which = 2)
```

Residuals vs. Leverage:

In this plot we examine the impact of an individual observation on the model, basically by checking how far from the average are the (possible) observations that do not fit in the model. In this case there is nothing to worry.

```{r}
plot(rg_model2, which = 5)
```
